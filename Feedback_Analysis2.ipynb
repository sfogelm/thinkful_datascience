{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amazon = pd.read_csv('/Users/spencerfogelman/Downloads/sentiment labelled sentences/amazon_cells_labelled.txt', header=None, delimiter='\\t').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amazon.columns = ['Message', 'Classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Message  Classification\n",
      "0  So there is no way for me to plug it in here i...               0\n",
      "1                        Good case, Excellent value.               1\n",
      "2                             Great for the jawbone.               1\n",
      "3  Tied to charger for conversations lasting more...               0\n",
      "4                                  The mic is great.               1\n",
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(amazon.head())\n",
    "print(amazon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    500\n",
       "0    500\n",
       "Name: Classification, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon['Classification'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(1000, 7895)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "text = amazon[\"Message\"]\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "X = vectorizer.fit_transform(text).toarray()\n",
    "print(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = amazon['Classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " '10 minutes',\n",
       " '10 of',\n",
       " '10 series',\n",
       " '100',\n",
       " '100 functional',\n",
       " '11',\n",
       " '11 months',\n",
       " '12',\n",
       " '12 minutes',\n",
       " '13',\n",
       " '13 bucks',\n",
       " '15',\n",
       " '15 seconds',\n",
       " '15g',\n",
       " '15g and',\n",
       " '18',\n",
       " '18 months',\n",
       " '20',\n",
       " '20 feet',\n",
       " '20 left',\n",
       " '2000',\n",
       " '2005',\n",
       " '2005 just',\n",
       " '2160',\n",
       " '2160 from',\n",
       " '24',\n",
       " '24 hours',\n",
       " '2mp',\n",
       " '2mp and',\n",
       " '325',\n",
       " '325 cellphone',\n",
       " '350',\n",
       " '350 headset',\n",
       " '375',\n",
       " '375 and',\n",
       " '3o',\n",
       " '3o minutes',\n",
       " '42',\n",
       " '42 usb',\n",
       " '44',\n",
       " '44 until',\n",
       " '45',\n",
       " '45 minutes',\n",
       " '4s',\n",
       " '4s despite',\n",
       " '50',\n",
       " '50 cent',\n",
       " '50 down',\n",
       " '5020']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98625\n",
      "0.765\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "print(bnb.score(X_train, y_train))\n",
    "print(bnb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84 0.83 0.86 0.79 0.81 0.74 0.77 0.78 0.8  0.78]\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(bnb, X, y, cv=10))\n",
    "print(cross_val_score(bnb, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 7895)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer_new = TfidfVectorizer()\n",
    "X_new = vectorizer_new.fit_transform(text).toarray()\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bnb_new = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9675"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test, y_train,y_test = train_test_split(X_new, y, test_size=0.2, random_state=1)\n",
    "bnb_new.fit(X_train, y_train)\n",
    "bnb_new.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.795"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb_new.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9875\n",
      "0.81\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "steps = [('vectorizer', TfidfVectorizer()),\n",
    "        ('bnb', BernoulliNB())]\n",
    "pipeline = Pipeline(steps)\n",
    "parameters = {'vectorizer__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "             'vectorizer__stop_words': [None, 'english'],\n",
    "              'vectorizer__norm': ['l1', 'l2'],\n",
    "              'vectorizer__min_df': [0.01, 0.05, 0.1, 1],\n",
    "              'vectorizer__max_df': [0.8, 0.9, 1.0]\n",
    "             }\n",
    "X = amazon['Message']\n",
    "y = amazon['Classification']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "cv.fit(X_train, y_train)\n",
    "print(cv.score(X_train, y_train))\n",
    "print(cv.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#How to do tfidf on only subset of data?\n",
    "#length of uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vectorizer__max_df': 0.8, 'vectorizer__norm': 'l1', 'vectorizer__min_df': 1, 'vectorizer__stop_words': 'english', 'vectorizer__ngram_range': (1, 3)}\n"
     ]
    }
   ],
   "source": [
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Message  Classification  \\\n",
      "0  So there is no way for me to plug it in here i...               0   \n",
      "1                        Good case, Excellent value.               1   \n",
      "2                             Great for the jawbone.               1   \n",
      "3  Tied to charger for conversations lasting more...               0   \n",
      "4                                  The mic is great.               1   \n",
      "\n",
      "   Text_length  \n",
      "0           82  \n",
      "1           27  \n",
      "2           22  \n",
      "3           79  \n",
      "4           17  \n"
     ]
    }
   ],
   "source": [
    "amazon['Text_length'] = amazon['Message'].apply(lambda x: len(x))\n",
    "print(amazon.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
